{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"load_model.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"9ba2be571938486486868f489b05041d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1ebec4f26be94dbc9d4e49216327d6ee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_86a635848577426f884005054361f6da","IPY_MODEL_c1aabfacecc74847b464f52ab914ceb8"]}},"1ebec4f26be94dbc9d4e49216327d6ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86a635848577426f884005054361f6da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b001e9c9d7504b7bbcd499d9fa9f379a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2337f59f7a78411e984b3ca134bfe0fc"}},"c1aabfacecc74847b464f52ab914ceb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_54ac03025eed4298b6fe1949497216ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 3.97MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72290c82986d492cbee90df71d446813"}},"b001e9c9d7504b7bbcd499d9fa9f379a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2337f59f7a78411e984b3ca134bfe0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54ac03025eed4298b6fe1949497216ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72290c82986d492cbee90df71d446813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwD_cdWg-4A-","executionInfo":{"status":"ok","timestamp":1613376910375,"user_tz":-540,"elapsed":13326,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"0daac7c4-2322-4f62-b5b2-2d9abff1615c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"semspXs8_N7y","executionInfo":{"status":"ok","timestamp":1613376915448,"user_tz":-540,"elapsed":18391,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"6474bece-1bdb-475a-e720-c4f0f3d6c687"},"source":["!pip install wget"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=888502dcc38c7c51a4f2f4fafe6558fd246bc4a7a27995ca666ee5764e0d9698\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AuwkUOsc_CdG"},"source":["# wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json', out='./bert-base-multilingual-cased/')\r\n","# os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-config.json', './bert-base-multilingual-cased/config.json')\r\n","# wget.download('https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-tf_model.h5', out='./bert-base-multilingual-cased/')\r\n","# os.rename('./bert-base-multilingual-cased/bert-base-multilingual-cased-tf_model.h5', './bert-base-multilingual-cased/tf_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNf1RCw8-4BC","executionInfo":{"status":"ok","timestamp":1613376931076,"user_tz":-540,"elapsed":34016,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"16029a86-b2ef-4ea2-a9bc-c94a3c344823"},"source":["!pip install tensorflow-addons\n","!pip install tokenizers\n","!pip install transformers\n","!pip install wget"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/af/0ce633c373d2b0476ef8299673d22275fcc3c5ba283b2cec4aa06bc5b810/tensorflow_addons-0.12.1-cp36-cp36m-manylinux2010_x86_64.whl (703kB)\n","\u001b[K     |████████████████████████████████| 706kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.12.1\n","Collecting tokenizers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 5.3MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.10.1\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 19.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=2c9ecc0476ba606a1a4cc2c5d9659c657808e774f91ccc304f621e0ad02150e5\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 transformers-4.3.2\n","Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oqae_mvr-4BD","executionInfo":{"status":"ok","timestamp":1613376933248,"user_tz":-540,"elapsed":23947,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["import os\n","import re\n","import json\n","import string\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tokenizers import BertWordPieceTokenizer\n","from transformers import BertTokenizer, TFBertModel\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import urllib\n","import wget\n","\n","MAX_LEN = 511\n","EPOCHS = 3\n","VERBOSE = 2\n","BATCH_SIZE = 8"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"WesAifb3-4BD","executionInfo":{"status":"ok","timestamp":1613376933250,"user_tz":-540,"elapsed":22213,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["DATA_OUT_PATH = '/content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/src'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aQkcZuw-4BD","executionInfo":{"status":"ok","timestamp":1613376933251,"user_tz":-540,"elapsed":20778,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["def plot_graphs(history, string, string_1, string_2):\n","    # loss \n","    plt.plot(history.history[string])\n","    plt.plot(history.history[string_1])\n","    plt.plot(history.history[string_2])\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(string)\n","    plt.legend([string, string_1, string_2])\n","    plt.show()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4UOQSQw-4BE","executionInfo":{"status":"ok","timestamp":1613376933252,"user_tz":-540,"elapsed":19931,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["SEED_NUM = 1234\n","tf.random.set_seed(SEED_NUM)\n","np.random.seed(SEED_NUM)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyD8IIHQ-4BE","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9ba2be571938486486868f489b05041d","1ebec4f26be94dbc9d4e49216327d6ee","86a635848577426f884005054361f6da","c1aabfacecc74847b464f52ab914ceb8","b001e9c9d7504b7bbcd499d9fa9f379a","2337f59f7a78411e984b3ca134bfe0fc","54ac03025eed4298b6fe1949497216ae","72290c82986d492cbee90df71d446813"]},"executionInfo":{"status":"ok","timestamp":1613376933877,"user_tz":-540,"elapsed":19170,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"f19f80ab-559b-4472-c52e-957483af9f20"},"source":["# Save the slow pretrained tokenizer\n","slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", lowercase=False)\n","save_path = \"bert-base-multilingual-cased/\"\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","slow_tokenizer.save_pretrained(save_path)\n","\n","# Load the fast tokenizer from saved file\n","tokenizer = BertWordPieceTokenizer(\"bert-base-multilingual-cased/vocab.txt\", lowercase=False)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ba2be571938486486868f489b05041d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XsdOKpGo-4BE","executionInfo":{"status":"ok","timestamp":1613376934262,"user_tz":-540,"elapsed":17928,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["class SquadExample:\n","    def __init__(self, question, context, start_char_idx, answer_text):\n","        self.question = question\n","        self.context = context\n","        self.start_char_idx = start_char_idx\n","        self.answer_text = answer_text\n","        self.skip = False\n","\n","    def preprocess(self):\n","        context = self.context\n","        question = self.question\n","        answer_text = self.answer_text\n","        start_char_idx = self.start_char_idx\n","\n","        # Clean context, answer and question\n","        context = \" \".join(str(context).split())\n","        question = \" \".join(str(question).split())\n","        answer = \" \".join(str(answer_text).split())\n","\n","        # Find end character index of answer in context\n","        end_char_idx = start_char_idx + len(answer)\n","        if end_char_idx >= len(context):\n","            self.skip = True\n","            return\n","\n","        # Mark the character indexes in context that are in answer\n","        is_char_in_ans = [0] * len(context)\n","        for idx in range(start_char_idx, end_char_idx):\n","            is_char_in_ans[idx] = 1\n","\n","        # Tokenize context\n","        tokenized_context = tokenizer.encode(context)\n","\n","        # Find tokens that were created from answer characters\n","        ans_token_idx = []\n","        for idx, (start, end) in enumerate(tokenized_context.offsets):\n","            if sum(is_char_in_ans[start:end]) > 0:\n","                ans_token_idx.append(idx)\n","\n","        if len(ans_token_idx) == 0:\n","            self.skip = True\n","            return\n","\n","        # Find start and end token index for tokens from answer\n","        start_token_idx = ans_token_idx[0]\n","        end_token_idx = ans_token_idx[-1]\n","\n","        # Tokenize question\n","        tokenized_question = tokenizer.encode(question)\n","\n","        # Create inputs\n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n","            tokenized_question.ids[1:]\n","        )\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Pad and create attention masks.\n","        # Skip if truncation is needed\n","        padding_length = MAX_LEN - len(input_ids)\n","        if padding_length > 0:  # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length)\n","            token_type_ids = token_type_ids + ([0] * padding_length)\n","        elif padding_length < 0:  # skip\n","            self.skip = True\n","            return\n","        \n","        #함정카드\n","        # Truncate the comments\n","        if len(input_ids) >  512:\n","            input_ids = input_ids[0:128] + input_ids[-382:-1]\n","            attention_mask = attention_mask[0:128] + attention_mask[-382:-1]\n","            token_type_ids = token_type_ids[0:128] + token_type_ids[-382:-1]\n","        #####\n","        \n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.start_token_idx = start_token_idx\n","        self.end_token_idx = end_token_idx\n","        self.context_token_to_char = tokenized_context.offsets\n","\n","\n","def create_squad_examples(raw_data):\n","    squad_examples = []\n","    for item in raw_data[\"data\"]:\n","        for para in item[\"paragraphs\"]:\n","            context = para[\"context\"]\n","            for qa in para[\"qas\"]:\n","                question = qa[\"question\"]\n","                answer_text = qa[\"answers\"][0][\"text\"]\n","                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n","                squad_eg = SquadExample(\n","                    question, context, start_char_idx, answer_text\n","                )\n","                squad_eg.preprocess()\n","                squad_examples.append(squad_eg)\n","    return squad_examples\n","\n","\n","def create_inputs_targets(squad_examples):\n","    dataset_dict = {\n","        \"input_ids\": [],\n","        \"token_type_ids\": [],\n","        \"attention_mask\": [],\n","        \"start_token_idx\": [],\n","        \"end_token_idx\": [],\n","    }\n","    for item in squad_examples:\n","        #item = suqand_example class\n","        if item.skip == False:\n","            for key in dataset_dict:\n","                dataset_dict[key].append(getattr(item, key))\n","    for key in dataset_dict:\n","        dataset_dict[key] = np.array(dataset_dict[key])\n","\n","    x = [\n","        dataset_dict[\"input_ids\"],\n","        dataset_dict[\"token_type_ids\"],\n","        dataset_dict[\"attention_mask\"],\n","    ]\n","    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n","    return x, y\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYePpe-9-4BF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613376940248,"user_tz":-540,"elapsed":19862,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"ebd983ba-f049-4e49-bf65-64a05a73fc67"},"source":["#Data input\n","path = '/content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/src/'\n","with open(path+'extract_train_data.json') as f:\n","    raw_train_data = json.load(f)\n","\n","with open(path+'extract_dev_data.json') as f:\n","    raw_eval_data = json.load(f)\n","\n","\n","train_squad_examples = create_squad_examples(raw_train_data)\n","x_train, y_train = create_inputs_targets(train_squad_examples)\n","print(f\"{len(train_squad_examples)} training points created.\")\n","\n","eval_squad_examples = create_squad_examples(raw_eval_data)\n","x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n","print(f\"{len(eval_squad_examples)} evaluation points created.\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["3487 training points created.\n","435 evaluation points created.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FD7OB6yz-4BF","executionInfo":{"status":"ok","timestamp":1613376940248,"user_tz":-540,"elapsed":16613,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["class TFBERTQuestionAnswering(tf.keras.Model):\n","    def __init__(self, model_name, dir_path, num_class):\n","        super(TFBERTQuestionAnswering, self).__init__()\n","        \n","        self.encoder = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n","        self.start_logit = tf.keras.layers.Dense(num_class, name=\"start_logit\", use_bias=False)\n","        self.end_logit = tf.keras.layers.Dense(num_class, name=\"end_logit\", use_bias=False)\n","        self.flatten = tf.keras.layers.Flatten() \n","        self.softmax = tf.keras.layers.Activation(tf.keras.activations.softmax)\n","        \n","    def call(self, inputs):\n","        input_ids, token_type_ids, attention_mask = inputs\n","        embedding = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0]\n","        start_logits = self.start_logit(embedding)\n","        start_logits = self.flatten(start_logits)\n","        \n","        end_logits = self.end_logit(embedding)\n","        end_logits = self.flatten(end_logits)\n","        \n","        start_probs = self.softmax(start_logits)\n","        end_probs = self.softmax(end_logits)\n","    \n","        return start_probs, end_probs"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzgMrUE2-4BG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613377003422,"user_tz":-540,"elapsed":15306,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"e1e3b2ff-af8b-469e-9360-ff47152c0f6f"},"source":["import tensorflow_addons as tfa\n","korquad_model = TFBERTQuestionAnswering(model_name='/content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/src/bert-base-multilingual-cased/',dir_path='./src/bert_ckpt', num_class=1)\n","optimizer = tfa.optimizers.RectifiedAdam(lr=1e-5) #tf.keras.optimizers.RAdam(learning_rate=5e-5)\n","loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at /content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/src/bert-base-multilingual-cased/ were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/src/bert-base-multilingual-cased/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HyiDdgDd-4BG","executionInfo":{"status":"ok","timestamp":1613377004329,"user_tz":-540,"elapsed":903,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}}},"source":["import re\n","import string\n","from collections import Counter\n","def normalize_answer(s):    \n","    def remove_(text):\n","        ''' 불필요한 기호 제거 '''\n","        text = re.sub(\"'\", \" \", text)\n","        text = re.sub('\"', \" \", text)\n","        text = re.sub('《', \" \", text)\n","        text = re.sub('》', \" \", text)\n","        text = re.sub('<', \" \", text)\n","        text = re.sub('>', \" \", text) \n","        text = re.sub('〈', \" \", text)\n","        text = re.sub('〉', \" \", text)   \n","        text = re.sub(\"\\(\", \" \", text)\n","        text = re.sub(\"\\)\", \" \", text)\n","        text = re.sub(\"‘\", \" \", text)\n","        text = re.sub(\"’\", \" \", text)      \n","        return text\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_punc(lower(remove_(s))))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIIDtV2--4BG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613377073488,"user_tz":-540,"elapsed":69533,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"28f51d80-5fbd-448d-c1c9-ab2f7b2dee9e"},"source":["%cd /content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2/\n","# 모델 weight_load\n","\n","loaded = TFBERTQuestionAnswering(model_name='./src/bert-base-multilingual-cased/',dir_path='./src/bert_ckpt', num_class=1)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n","loaded.compile(optimizer=optimizer, loss=[loss, loss])\n","for_batch = [np.array([x_train[0][0]]),np.array([x_train[1][0]]),np.array([x_train[2][0]])]\n","for_batch_y = [np.array([y_train[0][0]]),np.array([y_train[1][0]])]\n","history = loaded.fit(\n","    for_batch,\n","    for_batch_y,\n","    epochs=1,  # For demonstration, 3 epochs are recommended\n","    verbose=VERBOSE,\n","    batch_size=16,\n","\n",")\n","loaded.load_weights('./src/6_epochs_extract_radam_weights.h5') #로드 후 프리딕트 연결"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/gdrive/Shareddrives/슈퍼학부생 CREW/hackathon_2-2\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at ./src/bert-base-multilingual-cased/ were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at ./src/bert-base-multilingual-cased/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fba5e3086c8>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fba7b7ec2a0> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fba5e3086c8>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: <cyfunction Socket.send at 0x7fba7b7ec2a0> is not a module, class, method, function, traceback, frame, or code object\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fba795c3c80> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fba795c3c80> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n","1/1 - 57s - loss: 12.1462 - output_1_loss: 6.0021 - output_2_loss: 6.1441\n"],"name":"stdout"}]}]}